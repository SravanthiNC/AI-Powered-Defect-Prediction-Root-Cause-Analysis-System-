{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "672d19fb",
   "metadata": {},
   "source": [
    "# Detailed Code Explanation: iPhone Production Line Analysis\n",
    "\n",
    "## 1. Data Collection Process\n",
    "\n",
    "We use two main datasets:\n",
    "\n",
    "### a) Main Unit Assembly Data (main_unit_df)\n",
    "```python\n",
    "def generate_main_unit_data(num_rows):\n",
    "    data = {\n",
    "        'USN': [f'USN{str(i+1).zfill(6)}' for i in range(num_rows)],  # Unique iPhone ID\n",
    "        'LINE': [f'LINE{str(random.randint(1,5)).zfill(3)}'],         # Production line number\n",
    "        'STAGE': [f'M{random.randint(1,5)}'],                         # Assembly stage\n",
    "        'VENDOR': [f'VENDOR{random.randint(1,5)}'],                   # Component supplier\n",
    "        'RESULTFLAG': ['T' or 'F'],                                   # Pass/Fail status\n",
    "        'A_ERRORCODE': [Error codes if failure occurs]                 # Specific error types\n",
    "    }\n",
    "```\n",
    "\n",
    "### b) Component Assembly Data (component_df)\n",
    "```python\n",
    "def generate_component_data(num_rows):\n",
    "    data = {\n",
    "        'USN_PRIMARY': [f'USN{str(i+1).zfill(6)}'],                   # Main iPhone reference\n",
    "        'SUB_USN': [f'CSN{str(random.randint(1,999999)).zfill(6)}'],  # Component ID\n",
    "        'STAGE': [f'C{random.randint(1,5)}'],                         # Component stage\n",
    "        'SFC_STAGE': ['BTL:Double Lock', 'BTN Conn', etc],            # Specific operations\n",
    "    }\n",
    "```\n",
    "\n",
    "### Data Integration Process:\n",
    "1. Collect main unit data from assembly line sensors\n",
    "2. Gather component-level data from sub-assembly stations\n",
    "3. Merge data using USN (Unique Serial Number) as the key\n",
    "4. Add temporal features (time stamps, shifts, etc.)\n",
    "5. Calculate derived metrics (cycle times, failure rates, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671ca1c4",
   "metadata": {},
   "source": [
    "## 2. ML Models Implementation\n",
    "\n",
    "### Data Preprocessing\n",
    "```python\n",
    "# Convert datetime columns and extract features\n",
    "for df in [main_unit_df, component_df]:\n",
    "    for col in ['TRNDATE', 'INSERTTIME']:\n",
    "        df[col] = pd.to_datetime(df[col])\n",
    "        df[f'{col}_hour'] = df[col].dt.hour    # Time of day patterns\n",
    "        df[f'{col}_day'] = df[col].dt.day      # Daily patterns\n",
    "        df[f'{col}_month'] = df[col].dt.month  # Monthly patterns\n",
    "\n",
    "# Encode categorical variables\n",
    "le = LabelEncoder()\n",
    "categorical_cols = ['LINE', 'WORKSTATION', 'STAGE', 'VENDOR']\n",
    "for col in categorical_cols:\n",
    "    df[f'{col}_encoded'] = le.fit_transform(df[col])\n",
    "```\n",
    "\n",
    "### Random Forest Model (For Overall Quality Prediction)\n",
    "```python\n",
    "rf_model = RandomForestClassifier(n_estimators=100)\n",
    "rf_model.fit(X_main_train, y_main_train)\n",
    "```\n",
    "- Uses 100 decision trees\n",
    "- Each tree sees different subset of data\n",
    "- Combines predictions for robust results\n",
    "\n",
    "### XGBoost Model (For Specific Defect Types)\n",
    "```python\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "xgb_model.fit(X_main_train, y_main_train)\n",
    "```\n",
    "- Gradient boosting for high accuracy\n",
    "- Better with imbalanced data\n",
    "- Handles missing values well\n",
    "\n",
    "### LSTM Model (For Time-Series Patterns)\n",
    "```python\n",
    "lstm_model = Sequential([\n",
    "    LSTM(50, input_shape=(timesteps, features)),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "```\n",
    "- Analyzes sequences of events\n",
    "- Learns long-term patterns\n",
    "- Predicts future failures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa03f258",
   "metadata": {},
   "source": [
    "## 3. Dashboard Features\n",
    "\n",
    "### Real-time Monitoring\n",
    "```python\n",
    "# Current Production Status\n",
    "def update_production_status():\n",
    "    total_units = len(main_unit_df['USN'].unique())\n",
    "    current_failure_rate = len(main_unit_df[main_unit_df['RESULTFLAG'] == 'F']) / len(main_unit_df)\n",
    "    return total_units, current_failure_rate\n",
    "```\n",
    "\n",
    "### Quality Analytics\n",
    "```python\n",
    "# Vendor Performance Analysis\n",
    "vendor_metrics = main_df.groupby('VENDOR').agg({\n",
    "    'RESULTFLAG': lambda x: (x == 'F').mean(),  # Failure rate per vendor\n",
    "    'USN': 'count'                              # Total units per vendor\n",
    "})\n",
    "\n",
    "# Stage Analysis\n",
    "stage_metrics = main_df.groupby('STAGE').agg({\n",
    "    'RESULTFLAG': lambda x: (x == 'F').mean(),  # Failure rate per stage\n",
    "    'USN': 'count'                              # Total units per stage\n",
    "})\n",
    "```\n",
    "\n",
    "### Cost Impact\n",
    "```python\n",
    "def calculate_cost_impact(main_df, cost_per_failure=1000):\n",
    "    vendor_costs = main_df[main_df['RESULTFLAG'] == 'F'].groupby('VENDOR')['USN'].count()\n",
    "    vendor_costs = vendor_costs * cost_per_failure\n",
    "    return vendor_costs\n",
    "```\n",
    "\n",
    "### Predictive Alerts\n",
    "```python\n",
    "def predict_failure_risk(current_unit):\n",
    "    features = prepare_features(current_unit)\n",
    "    risk_score = rf_model.predict_proba(features)[0][1]\n",
    "    return risk_score > 0.7  # Alert if risk > 70%\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4e7c23",
   "metadata": {},
   "source": [
    "## 4. Implementation Steps for Production Line\n",
    "\n",
    "### Phase 1: Data Collection Setup\n",
    "1. Install sensors at key points:\n",
    "   - Battery assembly station\n",
    "   - Screen fitting station\n",
    "   - Final assembly checkpoints\n",
    "\n",
    "2. Configure data collection:\n",
    "```python\n",
    "# Real-time data collection\n",
    "def collect_production_data(station_id):\n",
    "    timestamp = datetime.now()\n",
    "    sensor_data = read_sensor(station_id)\n",
    "    quality_metrics = analyze_metrics(sensor_data)\n",
    "    return {\n",
    "        'timestamp': timestamp,\n",
    "        'station': station_id,\n",
    "        'metrics': quality_metrics\n",
    "    }\n",
    "```\n",
    "\n",
    "### Phase 2: Model Integration\n",
    "1. Deploy prediction models:\n",
    "```python\n",
    "# Load trained models\n",
    "rf_model = joblib.load('manufacturing_quality_model.joblib')\n",
    "scaler = joblib.load('feature_scaler.joblib')\n",
    "\n",
    "# Real-time prediction function\n",
    "def predict_quality(current_data):\n",
    "    features = preprocess_data(current_data)\n",
    "    prediction = rf_model.predict(features)\n",
    "    return prediction\n",
    "```\n",
    "\n",
    "### Phase 3: Dashboard Deployment\n",
    "1. Set up real-time monitoring:\n",
    "```python\n",
    "# Streamlit dashboard update\n",
    "def update_dashboard():\n",
    "    st.metric(\"Current Production Rate\", production_rate)\n",
    "    st.metric(\"Quality Score\", quality_score)\n",
    "    plot_failure_trends()\n",
    "```\n",
    "\n",
    "### Phase 4: Integration with Production Systems\n",
    "1. Connect with iPhone assembly line:\n",
    "```python\n",
    "# Production line integration\n",
    "def monitor_production_line():\n",
    "    while True:\n",
    "        current_unit = get_current_unit()\n",
    "        prediction = predict_quality(current_unit)\n",
    "        if prediction == 'F':\n",
    "            trigger_alert(current_unit)\n",
    "        update_dashboard()\n",
    "        time.sleep(update_interval)\n",
    "```\n",
    "\n",
    "2. Configure alert thresholds:\n",
    "```python\n",
    "alert_thresholds = {\n",
    "    'high_risk': 0.8,    # 80% failure probability\n",
    "    'medium_risk': 0.5,  # 50% failure probability\n",
    "    'low_risk': 0.2      # 20% failure probability\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ed76fa",
   "metadata": {},
   "source": [
    "## 5. Data Comparison and Integration\n",
    "\n",
    "### Linking Main Unit and Component Data\n",
    "```python\n",
    "def integrate_data(main_unit_df, component_df):\n",
    "    # Join datasets on USN\n",
    "    merged_data = pd.merge(\n",
    "        main_unit_df,\n",
    "        component_df,\n",
    "        left_on='USN',\n",
    "        right_on='USN_PRIMARY',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Calculate combined metrics\n",
    "    merged_data['total_failures'] = (\n",
    "        (merged_data['RESULTFLAG_x'] == 'F') |\n",
    "        (merged_data['RESULTFLAG_y'] == 'F')\n",
    "    ).astype(int)\n",
    "    \n",
    "    return merged_data\n",
    "```\n",
    "\n",
    "### Cross-Dataset Analysis\n",
    "```python\n",
    "def analyze_failure_patterns(merged_data):\n",
    "    # Component impact on main unit\n",
    "    component_impact = merged_data.groupby('SUB_USN').agg({\n",
    "        'RESULTFLAG_x': lambda x: (x == 'F').mean(),\n",
    "        'USN': 'count'\n",
    "    })\n",
    "    \n",
    "    # Stage correlation\n",
    "    stage_correlation = pd.crosstab(\n",
    "        merged_data['STAGE_x'],\n",
    "        merged_data['STAGE_y'],\n",
    "        values=merged_data['total_failures'],\n",
    "        aggfunc='mean'\n",
    "    )\n",
    "    \n",
    "    return component_impact, stage_correlation\n",
    "```\n",
    "\n",
    "### Predictive Features from Both Datasets\n",
    "```python\n",
    "def create_combined_features(merged_data):\n",
    "    features = {\n",
    "        'main_unit_stage': merged_data['STAGE_x_encoded'],\n",
    "        'component_stage': merged_data['STAGE_y_encoded'],\n",
    "        'vendor_main': merged_data['VENDOR_x_encoded'],\n",
    "        'vendor_component': merged_data['VENDOR_y_encoded'],\n",
    "        'time_features': [\n",
    "            merged_data['TRNDATE_x_hour'],\n",
    "            merged_data['TRNDATE_y_hour']\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    return pd.DataFrame(features)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
